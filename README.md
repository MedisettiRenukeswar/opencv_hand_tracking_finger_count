# âœ‹ OpenCV Hand Tracking & Finger Counting (Webcam)

This project uses **classical computer vision** (no deep learning) to perform:

- Real-time **hand tracking**
- **Skin-based segmentation** inside a Region of Interest (ROI)
- **Contour + convex hull** extraction
- **Convexity defects** analysis to estimate **number of extended fingers**

Input: Webcam  
Output: Live view with:
- ROI box
- Hand contour + convex hull
- Marked finger gaps
- `Fingers: N` overlay

---

## ğŸ¯ What this repo demonstrates

- Using webcam frames as a **real-time CV input**
- Skin detection in **YCrCb color space**
- Extracting the **largest contour** as the hand
- Computing **convex hull** of the hand
- Extracting **convexity defects** (valleys between fingers)
- Converting defects into **finger count** using geometry (angles + depth)
- Overlaying the result live + saving snapshots

---

## ğŸ“‚ Project Structure

```text
opencv-hand-tracking-finger-count/
â”‚
â”œâ”€â”€ main.py          # Webcam hand tracking + finger counting
â”œâ”€â”€ requirements.txt # Dependencies (opencv-python, numpy)
â”œâ”€â”€ outputs/         # Saved annotated snapshots
â””â”€â”€ README.md
```
## ğŸš€ How to Run

### 1ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run the script
```bash
python main.py
```

### 3ï¸âƒ£ Controls
- `q` â†’ quit
- `s` â†’ save current frame (annotated) into `outputs/`

Place your hand inside the yellow ROI box in the camera view.
Try:

- 0 fingers (fist)
``- 1, 2, 3, 4, 5 fingers

Youâ€™ll see the finger count update in real-time.

## ğŸ” How It Works â€” Step-by-Step

### **1. Region of Interest (ROI)**
The system does **not** process the full webcam frame.  
Instead, it tracks only a fixed rectangular region where you place your hand.  
This reduces noise, improves segmentation, and boosts FPS.

---

### **2. Skin Detection (YCrCb Color Space)**

Inside the ROI:

- Convert **BGR â†’ YCrCb**
- Apply skin thresholds:

```text
Cr: 133â€“173
Cb: 77â€“127
```

- Apply morphological operations (erode, dilate, blur) to clean up the mask

Result: binary skin mask where the hand appears as a large white region.

---


- Clean the binary mask using:
  - **Erosion**
  - **Dilation**
  - **Gaussian blur**

The result is a **white hand region** on a black background.

---

### **3. Contour Extraction**

From the cleaned skin mask:

1. Find **all contours**
2. Keep only the **largest contour** (assumed hand)
3. Draw:
   - **Yellow contour** â†’ hand outline  
   - **Green hull** â†’ convex hull shape  

If no valid contour is found â†’ output **0 fingers**.

---

### **4. Convexity Defects â†’ Finger Counting**

Using the largest contour:

1. Compute convex hull (indices)
2. Use `cv2.convexityDefects` to identify **valleys between fingers**
3. For each defect:
   - Compute triangle edges (**a**, **b**, **c**)
   - Use **cosine rule** to find the angle at the valley
   - Evaluate the **defect depth**

A defect is valid when:

- **Angle** is below a threshold (e.g., 80Â°)
- **Depth** is above a threshold (e.g., 20px)

Each valid defect corresponds to a **finger gap**.

ğŸ‘‰ **Finger count = valid defects + 1**  
(Maximum clamped to **5 fingers** for stability.)

---

### **5. Overlay + Output**

Overlay the finger count on the frame and display it in real-time.

---

## ğŸ“Œ Notes

- The finger count is **not** perfect.  
  Itâ€™s a simple heuristic based on convexity defects.
- The finger count is **not** perfect.  
  Itâ€™s a simple heuristic based on convexity defects.

---

## ğŸ¨ On-Screen Visualization

The system overlays helpful visual cues to show *exactly* how the hand is being analyzed:

- **Yellow contour** â†’ detected hand outline  
- **Green convex hull** â†’ smoothed outer boundary  
- **Red markers** â†’ convexity defect points (valleys between fingers)  
- **Text (top-left):**  
  - `Fingers: N` â†’ finger count  
  - `FPS: N` â†’ current FPS

---

### ğŸ“¸ Outputs

Below are typical output frames generated by the system:
```text
outputs/
â”‚
â”œâ”€â”€ 2/
â”‚   â”œâ”€â”€ image1-2.jpg
â”‚   â”œâ”€â”€ image2-2.jpg
â”‚   â”œâ”€â”€ image3-2.jpg
â”‚   â””â”€â”€ image4-2.jpg
â”œâ”€â”€ 3/
â”‚   â”œâ”€â”€ image1-3.jpg
â”‚   â”œâ”€â”€ image2-3.jpg
â”‚   â”œâ”€â”€ image3-3.jpg
â”‚   â””â”€â”€ image4-3.jpg
â”œâ”€â”€ 4/
â”‚   â”œâ”€â”€ image1-4.jpg
â”‚   â”œâ”€â”€ image2-4.jpg
â”‚   â””â”€â”€ image3-4.jpg
â”œâ”€â”€ 5/
â”‚   â”œâ”€â”€ image1-5.jpg
â”‚   â”œâ”€â”€ image2-5.jpg
â”‚   â””â”€â”€ image3-5.jpg
â””â”€â”€ 0/
    â”œâ”€â”€ image1-0.jpg

## ğŸ“ Finger Count Output Preview

| Finger Count | Preview |
|--------------|---------|
| **0 Fingers** | ![](outputs/image1-0.jpg) |
| **2 Fingers** | ![2-1](outputs/2/image1-2.jpg) ![2-2](outputs/2/image2-2.jpg) ![2-3](outputs/2/image3-2.jpg) ![2-4](outputs/2/image4-2.jpg) |
| **3 Fingers** | ![3-1](outputs/3/image1-3.jpg) ![3-2](outputs/3/image2-3.jpg) ![3-3](outputs/3/image3-3.jpg) ![3-4](outputs/3/image4-3.jpg) |
| **4 Fingers** | ![4-1](outputs/4/image1-4.jpg) ![4-2](outputs/4/image2-4.jpg) ![4-3](outputs/4/image3-4.jpg) |
| **5 Fingers** | ![5-1](outputs/5/image1-5.jpg) ![5-2](outputs/5/image2-5.jpg) ![5-3](outputs/5/image3-5.jpg) |

---

## âš ï¸ Limitations

This classical CV method is intentionally simple, so it has weaknesses:

- Highly sensitive to **lighting conditions**
- Skin tone variations affect segmentation
- Complex or cluttered background inside ROI breaks masking
- Shadows, highlights, reflections can cause false contours
- Extreme hand rotations confuse convexity defect logic

These limitations are **the reason modern deep networks exist**.

---

## ğŸ§  Why This Project Matters

This repo teaches the fundamentals behind early computer vision gesture systems:

### Useful Applications
- Gesture-based UI/UX  
- Humanâ€“Computer Interaction (HCI)  
- Simple robot teleoperation  
- AR/VR gesture input  
- Basic HRI (Humanâ€“Robot Interaction)  
- Educational CV experiments  

### What You Learn
âœ” How geometric CV pipelines work  
âœ” Why convex hulls + defects can detect fingers  
âœ” Where classical CV breaks down  
âœ” How traditional techniques evolved into deep-learning models  
âœ” The importance of segmentation â†’ contour â†’ hull â†’ defects  

This foundational understanding will make you far better at using modern tools like:

- **MediaPipe Hands**
- **YOLO-based hand detection**
- **Deep hand pose estimation models**
- **Gesture recognition networks**

You now understand the *entire classical pipeline*, end-to-end.
